# sweep_config.yaml

method: random  # You can use 'grid' or 'random'
name: hyperparameter_sweep
metric:
  name: loss  # You can track any metric you want to optimize
  goal: minimize  # 'maximize' or 'minimize' based on your goal
parameters:
  batch_size:
    values: [16, 32, 64]  # Example batch sizes
  learning_rate:
    min: 1e-5
    max: 1e-2
    distribution: log_uniform  # Log scale for continuous hyperparameters
  optimizer:
    values: ['adam', 'sgd']  # Example optimizers to test
  input_dim:
    values: [32]
  hidden_dim:
      values: [64, 128]
  output_dim:
      values: [10]
  epochs:
      values: [5, 10]
